msgid ""
msgstr ""
"Project-Id-Version: The Embedded Rust Book\n"
"POT-Creation-Date: 2025-12-02T17:24:39Z\n"
"PO-Revision-Date: \n"
"Last-Translator: \n"
"Language-Team: \n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: src/concurrency/index.md:1
msgid "Concurrency"
msgstr ""

#: src/concurrency/index.md:3
msgid ""
"Concurrency happens whenever different parts of your program might execute "
"at different times or out of order. In an embedded context, this includes:"
msgstr ""

#: src/concurrency/index.md:6
msgid ""
"interrupt handlers, which run whenever the associated interrupt happens,"
msgstr ""

#: src/concurrency/index.md:7
msgid ""
"various forms of multithreading, where your microprocessor regularly swaps "
"between parts of your program,"
msgstr ""

#: src/concurrency/index.md:9
msgid ""
"and in some systems, multiple-core microprocessors, where each core can be "
"independently running a different part of your program at the same time."
msgstr ""

#: src/concurrency/index.md:12
msgid ""
"Since many embedded programs need to deal with interrupts, concurrency will "
"usually come up sooner or later, and it's also where many subtle and "
"difficult bugs can occur. Luckily, Rust provides a number of abstractions "
"and safety guarantees to help us write correct code."
msgstr ""

#: src/concurrency/index.md:17
msgid "No Concurrency"
msgstr ""

#: src/concurrency/index.md:19
msgid ""
"The simplest concurrency for an embedded program is no concurrency: your "
"software consists of a single main loop which just keeps running, and there "
"are no interrupts at all. Sometimes this is perfectly suited to the problem "
"at hand! Typically your loop will read some inputs, perform some processing, "
"and write some outputs."
msgstr ""

#: src/concurrency/index.md:37
msgid ""
"Since there's no concurrency, there's no need to worry about sharing data "
"between parts of your program or synchronising access to peripherals. If you "
"can get away with such a simple approach this can be a great solution."
msgstr ""

#: src/concurrency/index.md:41
msgid "Global Mutable Data"
msgstr ""

#: src/concurrency/index.md:43
msgid ""
"Unlike non-embedded Rust, we will not usually have the luxury of creating "
"heap allocations and passing references to that data into a newly-created "
"thread. Instead, our interrupt handlers might be called at any time and must "
"know how to access whatever shared memory we are using. At the lowest level, "
"this means we must have _statically allocated_ mutable memory, which both "
"the interrupt handler and the main code can refer to."
msgstr ""

#: src/concurrency/index.md:50
msgid ""
"In Rust, such [`static mut`](https://doc.rust-lang.org/book/ch19-01-unsafe-"
"rust.html#accessing-or-modifying-a-mutable-static-variable) variables are "
"always unsafe to read or write, because without taking special care, you "
"might trigger a race condition, where your access to the variable is "
"interrupted halfway through by an interrupt which also accesses that "
"variable."
msgstr ""

#: src/concurrency/index.md:57
msgid ""
"For an example of how this behaviour can cause subtle errors in your code, "
"consider an embedded program which counts rising edges of some input signal "
"in each one-second period (a frequency counter):"
msgstr ""

#: src/concurrency/index.md:71
msgid "// DANGER - Not actually safe! Could cause data races.\n"
msgstr ""

#: src/concurrency/index.md:84
msgid ""
"Each second, the timer interrupt sets the counter back to 0. Meanwhile, the "
"main loop continually measures the signal, and incremements the counter when "
"it sees a change from low to high. We've had to use `unsafe` to access "
"`COUNTER`, as it's `static mut`, and that means we're promising the compiler "
"we won't cause any undefined behaviour. Can you spot the race condition? The "
"increment on `COUNTER` is _not_ guaranteed to be atomic — in fact, on most "
"embedded platforms, it will be split into a load, then the increment, then a "
"store. If the interrupt fired after the load but before the store, the reset "
"back to 0 would be ignored after the interrupt returns — and we would count "
"twice as many transitions for that period."
msgstr ""

#: src/concurrency/index.md:95
msgid "Critical Sections"
msgstr ""

#: src/concurrency/index.md:97
msgid ""
"So, what can we do about data races? A simple approach is to use _critical "
"sections_, a context where interrupts are disabled. By wrapping the access "
"to `COUNTER` in `main` in a critical section, we can be sure the timer "
"interrupt will not fire until we're finished incrementing `COUNTER`:"
msgstr ""

#: src/concurrency/index.md:112
msgid "// New critical section ensures synchronised access to COUNTER\n"
msgstr ""

#: src/concurrency/index.md:127
msgid ""
"In this example, we use `cortex_m::interrupt::free`, but other platforms "
"will have similar mechanisms for executing code in a critical section. This "
"is also the same as disabling interrupts, running some code, and then re-"
"enabling interrupts."
msgstr ""

#: src/concurrency/index.md:132
msgid ""
"Note we didn't need to put a critical section inside the timer interrupt, "
"for two reasons:"
msgstr ""

#: src/concurrency/index.md:135
msgid ""
"Writing 0 to `COUNTER` can't be affected by a race since we don't read it"
msgstr ""

#: src/concurrency/index.md:136
msgid "It will never be interrupted by the `main` thread anyway"
msgstr ""

#: src/concurrency/index.md:138
msgid ""
"If `COUNTER` was being shared by multiple interrupt handlers that might "
"_preempt_ each other, then each one might require a critical section as well."
msgstr ""

#: src/concurrency/index.md:141
msgid ""
"This solves our immediate problem, but we're still left writing a lot of "
"unsafe code which we need to carefully reason about, and we might be using "
"critical sections needlessly. Since each critical section temporarily pauses "
"interrupt processing, there is an associated cost of some extra code size "
"and higher interrupt latency and jitter (interrupts may take longer to be "
"processed, and the time until they are processed will be more variable). "
"Whether this is a problem depends on your system, but in general, we'd like "
"to avoid it."
msgstr ""

#: src/concurrency/index.md:143
msgid ""
"It's worth noting that while a critical section guarantees no interrupts "
"will fire, it does not provide an exclusivity guarantee on multi-core "
"systems!  The other core could be happily accessing the same memory as your "
"core, even without interrupts. You will need stronger synchronisation "
"primitives if you are using multiple cores."
msgstr ""

#: src/concurrency/index.md:149
msgid "Atomic Access"
msgstr ""

#: src/concurrency/index.md:151
msgid ""
"On some platforms, special atomic instructions are available, which provide "
"guarantees about read-modify-write operations. Specifically for Cortex-M: "
"`thumbv6` (Cortex-M0, Cortex-M0+) only provide atomic load and store "
"instructions, while `thumbv7` (Cortex-M3 and above) provide full Compare and "
"Swap (CAS) instructions. These CAS instructions give an alternative to the "
"heavy-handed disabling of all interrupts: we can attempt the increment, it "
"will succeed most of the time, but if it was interrupted it will "
"automatically retry the entire increment operation. These atomic operations "
"are safe even across multiple cores."
msgstr ""

#: src/concurrency/index.md:173
msgid "// Use `fetch_add` to atomically add 1 to COUNTER\n"
msgstr ""

#: src/concurrency/index.md:182
msgid "// Use `store` to write 0 directly to COUNTER\n"
msgstr ""

#: src/concurrency/index.md:187
msgid ""
"This time `COUNTER` is a safe `static` variable. Thanks to the `AtomicUsize` "
"type `COUNTER` can be safely modified from both the interrupt handler and "
"the main thread without disabling interrupts. When possible, this is a "
"better solution — but it may not be supported on your platform."
msgstr ""

#: src/concurrency/index.md:192
msgid ""
"A note on [`Ordering`](https://doc.rust-lang.org/core/sync/atomic/enum."
"Ordering.html): this affects how the compiler and hardware may reorder "
"instructions, and also has consequences on cache visibility. Assuming that "
"the target is a single core platform `Relaxed` is sufficient and the most "
"efficient choice in this particular case. Stricter ordering will cause the "
"compiler to emit memory barriers around the atomic operations; depending on "
"what you're using atomics for you may or may not need this! The precise "
"details of the atomic model are complicated and best described elsewhere."
msgstr ""

#: src/concurrency/index.md:200
msgid ""
"For more details on atomics and ordering, see the [nomicon](https://doc.rust-"
"lang.org/nomicon/atomics.html)."
msgstr ""

#: src/concurrency/index.md:206
msgid "Abstractions, Send, and Sync"
msgstr ""

#: src/concurrency/index.md:208
msgid ""
"None of the above solutions are especially satisfactory. They require "
"`unsafe` blocks which must be very carefully checked and are not ergonomic. "
"Surely we can do better in Rust!"
msgstr ""

#: src/concurrency/index.md:212
msgid ""
"We can abstract our counter into a safe interface which can be safely used "
"anywhere else in our code. For this example, we'll use the critical-section "
"counter, but you could do something very similar with atomics."
msgstr ""

#: src/concurrency/index.md:219
msgid ""
"// Our counter is just a wrapper around UnsafeCell<u32>, which is the heart\n"
"// of interior mutability in Rust. By using interior mutability, we can "
"have\n"
"// COUNTER be `static` instead of `static mut`, but still able to mutate\n"
"// its counter value.\n"
msgstr ""

#: src/concurrency/index.md:230
msgid ""
"// By requiring a CriticalSection be passed in, we know we must\n"
"        // be operating inside a CriticalSection, and so can confidently\n"
"        // use this unsafe block (required to call UnsafeCell::get).\n"
msgstr ""

#: src/concurrency/index.md:240
msgid "// Required to allow static CSCounter. See explanation below.\n"
msgstr ""

#: src/concurrency/index.md:243
msgid ""
"// COUNTER is no longer `mut` as it uses interior mutability;\n"
"// therefore it also no longer requires unsafe blocks to access.\n"
msgstr ""

#: src/concurrency/index.md:255
msgid "// No unsafe here!\n"
msgstr ""

#: src/concurrency/index.md:264
msgid ""
"// We do need to enter a critical section here just to obtain a valid\n"
"    // cs token, even though we know no other interrupt could pre-empt\n"
"    // this one.\n"
msgstr ""

#: src/concurrency/index.md:269
msgid ""
"// We could use unsafe code to generate a fake CriticalSection if we\n"
"    // really wanted to, avoiding the overhead:\n"
"    // let cs = unsafe { interrupt::CriticalSection::new() };\n"
msgstr ""

#: src/concurrency/index.md:275
msgid ""
"We've moved our `unsafe` code to inside our carefully-planned abstraction, "
"and now our application code does not contain any `unsafe` blocks."
msgstr ""

#: src/concurrency/index.md:278
msgid ""
"This design requires that the application pass a `CriticalSection` token in: "
"these tokens are only safely generated by `interrupt::free`, so by requiring "
"one be passed in, we ensure we are operating inside a critical section, "
"without having to actually do the lock ourselves. This guarantee is provided "
"statically by the compiler: there won't be any runtime overhead associated "
"with `cs`. If we had multiple counters, they could all be given the same "
"`cs`, without requiring multiple nested critical sections."
msgstr ""

#: src/concurrency/index.md:286
msgid ""
"This also brings up an important topic for concurrency in Rust: the [`Send` "
"and `Sync`](https://doc.rust-lang.org/nomicon/send-and-sync.html) traits. To "
"summarise the Rust book, a type is Send when it can safely be moved to "
"another thread, while it is Sync when it can be safely shared between "
"multiple threads. In an embedded context, we consider interrupts to be "
"executing in a separate thread to the application code, so variables "
"accessed by both an interrupt and the main code must be Sync."
msgstr ""

#: src/concurrency/index.md:296
msgid ""
"For most types in Rust, both of these traits are automatically derived for "
"you by the compiler. However, because `CSCounter` contains an [`UnsafeCell`]"
"(https://doc.rust-lang.org/core/cell/struct.UnsafeCell.html), it is not "
"Sync, and therefore we could not make a `static CSCounter`: `static` "
"variables _must_ be Sync, since they can be accessed by multiple threads."
msgstr ""

#: src/concurrency/index.md:303
msgid ""
"To tell the compiler we have taken care that the `CSCounter` is in fact safe "
"to share between threads, we implement the Sync trait explicitly. As with "
"the previous use of critical sections, this is only safe on single-core "
"platforms: with multiple cores, you would need to go to greater lengths to "
"ensure safety."
msgstr ""

#: src/concurrency/index.md:308
msgid "Mutexes"
msgstr ""

#: src/concurrency/index.md:310
msgid ""
"We've created a useful abstraction specific to our counter problem, but "
"there are many common abstractions used for concurrency."
msgstr ""

#: src/concurrency/index.md:313
msgid ""
"One such _synchronisation primitive_ is a mutex, short for mutual exclusion. "
"These constructs ensure exclusive access to a variable, such as our counter. "
"A thread can attempt to _lock_ (or _acquire_) the mutex, and either succeeds "
"immediately, or blocks waiting for the lock to be acquired, or returns an "
"error that the mutex could not be locked. While that thread holds the lock, "
"it is granted access to the protected data. When the thread is done, it "
"_unlocks_ (or _releases_) the mutex, allowing another thread to lock it. In "
"Rust, we would usually implement the unlock using the [`Drop`](https://doc."
"rust-lang.org/core/ops/trait.Drop.html) trait to ensure it is always "
"released when the mutex goes out of scope."
msgstr ""

#: src/concurrency/index.md:325
msgid ""
"Using a mutex with interrupt handlers can be tricky: it is not normally "
"acceptable for the interrupt handler to block, and it would be especially "
"disastrous for it to block waiting for the main thread to release a lock, "
"since we would then _deadlock_ (the main thread will never release the lock "
"because execution stays in the interrupt handler). Deadlocking is not "
"considered unsafe: it is possible even in safe Rust."
msgstr ""

#: src/concurrency/index.md:332
msgid ""
"To avoid this behaviour entirely, we could implement a mutex which requires "
"a critical section to lock, just like our counter example. So long as the "
"critical section must last as long as the lock, we can be sure we have "
"exclusive access to the wrapped variable without even needing to track the "
"lock/unlock state of the mutex."
msgstr ""

#: src/concurrency/index.md:338
msgid ""
"This is in fact done for us in the `cortex_m` crate! We could have written "
"our counter using it:"
msgstr ""

#: src/concurrency/index.md:363
msgid ""
"// We still need to enter a critical section here to satisfy the Mutex.\n"
msgstr ""

#: src/concurrency/index.md:368
msgid ""
"We're now using [`Cell`](https://doc.rust-lang.org/core/cell/struct.Cell."
"html), which along with its sibling `RefCell` is used to provide safe "
"interior mutability. We've already seen `UnsafeCell` which is the bottom "
"layer of interior mutability in Rust: it allows you to obtain multiple "
"mutable references to its value, but only with unsafe code. A `Cell` is like "
"an `UnsafeCell` but it provides a safe interface: it only permits taking a "
"copy of the current value or replacing it, not taking a reference, and since "
"it is not Sync, it cannot be shared between threads. These constraints mean "
"it's safe to use, but we couldn't use it directly in a `static` variable as "
"a `static` must be Sync."
msgstr ""

#: src/concurrency/index.md:380
msgid ""
"So why does the example above work? The `Mutex<T>` implements Sync for any "
"`T` which is Send — such as a `Cell`. It can do this safely because it only "
"gives access to its contents during a critical section. We're therefore able "
"to get a safe counter with no unsafe code at all!"
msgstr ""

#: src/concurrency/index.md:385
msgid ""
"This is great for simple types like the `u32` of our counter, but what about "
"more complex types which are not Copy? An extremely common example in an "
"embedded context is a peripheral struct, which generally is not Copy. For "
"that, we can turn to `RefCell`."
msgstr ""

#: src/concurrency/index.md:390
msgid "Sharing Peripherals"
msgstr ""

#: src/concurrency/index.md:392
msgid ""
"Device crates generated using `svd2rust` and similar abstractions provide "
"safe access to peripherals by enforcing that only one instance of the "
"peripheral struct can exist at a time. This ensures safety, but makes it "
"difficult to access a peripheral from both the main thread and an interrupt "
"handler."
msgstr ""

#: src/concurrency/index.md:398
msgid ""
"To safely share peripheral access, we can use the `Mutex` we saw before. "
"We'll also need to use [`RefCell`](https://doc.rust-lang.org/core/cell/"
"struct.RefCell.html), which uses a runtime check to ensure only one "
"reference to a peripheral is given out at a time. This has more overhead "
"than the plain `Cell`, but since we are giving out references rather than "
"copies, we must be sure only one exists at a time."
msgstr ""

#: src/concurrency/index.md:406
msgid ""
"Finally, we'll also have to account for somehow moving the peripheral into "
"the shared variable after it has been initialised in the main code. To do "
"this we can use the `Option` type, initialised to `None` and later set to "
"the instance of the peripheral."
msgstr ""

#: src/concurrency/index.md:421
msgid ""
"// Obtain the peripheral singletons and configure it.\n"
"    // This example is from an svd2rust-generated crate, but\n"
"    // most embedded device crates will be similar.\n"
msgstr ""

#: src/concurrency/index.md:427
msgid ""
"// Some sort of configuration function.\n"
"    // Assume it sets PA0 to an input and PA1 to an output.\n"
msgstr ""

#: src/concurrency/index.md:431
msgid "// Store the GPIOA in the mutex, moving it.\n"
msgstr ""

#: src/concurrency/index.md:433
msgid ""
"// We can no longer use `gpioa` or `dp.GPIOA`, and instead have to\n"
"    // access it via the mutex.\n"
msgstr ""

#: src/concurrency/index.md:436
msgid ""
"// Be careful to enable the interrupt only after setting MY_GPIO:\n"
"    // otherwise the interrupt might fire while it still contains None,\n"
"    // and as-written (with `unwrap()`), it would panic.\n"
msgstr ""

#: src/concurrency/index.md:442
msgid "// We'll now read state as a digital input, via the mutex\n"
msgstr ""

#: src/concurrency/index.md:449
msgid "// Set PA1 high if we've seen a rising edge on PA0.\n"
msgstr ""

#: src/concurrency/index.md:461
msgid "// This time in the interrupt we'll just clear PA0.\n"
msgstr ""

#: src/concurrency/index.md:463
msgid ""
"// We can use `unwrap()` because we know the interrupt wasn't enabled\n"
"        // until after MY_GPIO was set; otherwise we should handle the "
"potential\n"
"        // for a None value.\n"
msgstr ""

#: src/concurrency/index.md:472
msgid "That's quite a lot to take in, so let's break down the important lines."
msgstr ""

#: src/concurrency/index.md:479
msgid ""
"Our shared variable is now a `Mutex` around a `RefCell` which contains an "
"`Option`. The `Mutex` ensures we only have access during a critical section, "
"and therefore makes the variable Sync, even though a plain `RefCell` would "
"not be Sync. The `RefCell` gives us interior mutability with references, "
"which we'll need to use our `GPIOA`. The `Option` lets us initialise this "
"variable to something empty, and only later actually move the variable in. "
"We cannot access the peripheral singleton statically, only at runtime, so "
"this is required."
msgstr ""

#: src/concurrency/index.md:492
msgid ""
"Inside a critical section we can call `borrow()` on the mutex, which gives "
"us a reference to the `RefCell`. We then call `replace()` to move our new "
"value into the `RefCell`."
msgstr ""

#: src/concurrency/index.md:503
msgid ""
"Finally, we use `MY_GPIO` in a safe and concurrent fashion. The critical "
"section prevents the interrupt firing as usual, and lets us borrow the "
"mutex.  The `RefCell` then gives us an `&Option<GPIOA>`, and tracks how long "
"it remains borrowed - once that reference goes out of scope, the `RefCell` "
"will be updated to indicate it is no longer borrowed."
msgstr ""

#: src/concurrency/index.md:509
msgid ""
"Since we can't move the `GPIOA` out of the `&Option`, we need to convert it "
"to an `&Option<&GPIOA>` with `as_ref()`, which we can finally `unwrap()` to "
"obtain the `&GPIOA` which lets us modify the peripheral."
msgstr ""

#: src/concurrency/index.md:513
msgid ""
"If we need a mutable reference to a shared resource, then `borrow_mut` and "
"`deref_mut` should be used instead. The following code shows an example "
"using the TIM2 timer."
msgstr ""

#: src/concurrency/index.md:531
msgid ""
"// Some sort of timer configuration function.\n"
"    // Assume it configures the TIM2 timer, its NVIC interrupt,\n"
"    // and finally starts the timer.\n"
msgstr ""

#: src/concurrency/index.md:556
msgid ""
"Whew! This is safe, but it is also a little unwieldy. Is there anything else "
"we can do?"
msgstr ""

#: src/concurrency/index.md:559
msgid "RTIC"
msgstr ""

#: src/concurrency/index.md:561
msgid ""
"One alternative is the [RTIC framework](https://github.com/rtic-rs/cortex-m-"
"rtic), short for Real Time Interrupt-driven Concurrency. It enforces static "
"priorities and tracks accesses to `static mut` variables (\"resources\") to "
"statically ensure that shared resources are always accessed safely, without "
"requiring the overhead of always entering critical sections and using "
"reference counting (as in `RefCell`). This has a number of advantages such "
"as guaranteeing no deadlocks and giving extremely low time and memory "
"overhead."
msgstr ""

#: src/concurrency/index.md:570
msgid ""
"The framework also includes other features like message passing, which "
"reduces the need for explicit shared state, and the ability to schedule "
"tasks to run at a given time, which can be used to implement periodic tasks. "
"Check out [the documentation](https://rtic.rs) for more information!"
msgstr ""

#: src/concurrency/index.md:577
msgid "Real Time Operating Systems"
msgstr ""

#: src/concurrency/index.md:579
msgid ""
"Another common model for embedded concurrency is the real-time operating "
"system (RTOS). While currently less well explored in Rust, they are widely "
"used in traditional embedded development. Open source examples include "
"[FreeRTOS](https://freertos.org/) and [ChibiOS](http://chibios.org/). These "
"RTOSs provide support for running multiple application threads which the CPU "
"swaps between, either when the threads yield control (called cooperative "
"multitasking) or based on a regular timer or interrupts (preemptive "
"multitasking). The RTOS typically provide mutexes and other synchronisation "
"primitives, and often interoperate with hardware features such as DMA "
"engines."
msgstr ""

#: src/concurrency/index.md:591
msgid ""
"At the time of writing, there are not many Rust RTOS examples to point to, "
"but it's an interesting area so watch this space!"
msgstr ""

#: src/concurrency/index.md:594
msgid "Multiple Cores"
msgstr ""

#: src/concurrency/index.md:596
msgid ""
"It is becoming more common to have two or more cores in embedded processors, "
"which adds an extra layer of complexity to concurrency. All the examples "
"using a critical section (including the `cortex_m::interrupt::Mutex`) assume "
"the only other execution thread is the interrupt thread, but on a multi-core "
"system that's no longer true. Instead, we'll need synchronisation primitives "
"designed for multiple cores (also called SMP, for symmetric multi-"
"processing)."
msgstr ""

#: src/concurrency/index.md:603
msgid ""
"These typically use the atomic instructions we saw earlier, since the "
"processing system will ensure that atomicity is maintained over all cores."
msgstr ""

#: src/concurrency/index.md:606
msgid ""
"Covering these topics in detail is currently beyond the scope of this book, "
"but the general patterns are the same as for the single-core case."
msgstr ""
